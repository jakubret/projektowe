{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.spatial.distance import cosine\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "pb_model_path = \"your_path\"\n",
    "\n",
    "def load_pb_model(pb_model_path):\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        graph_def = tf.compat.v1.GraphDef()\n",
    "        with tf.io.gfile.GFile(pb_model_path, \"rb\") as f:\n",
    "            graph_def.ParseFromString(f.read())\n",
    "            tf.import_graph_def(graph_def, name=\"\")\n",
    "    return graph\n",
    "\n",
    "graph = load_pb_model(pb_model_path)\n",
    "sess = tf.compat.v1.Session(graph=graph)\n",
    "\n",
    "images_placeholder = graph.get_tensor_by_name(\"input:0\")\n",
    "embeddings_tensor = graph.get_tensor_by_name(\"embeddings:0\")\n",
    "phase_train_placeholder = graph.get_tensor_by_name(\"phase_train:0\")\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image = tf.image.resize(image, (160, 160))  \n",
    "    image = tf.cast(image, dtype=tf.float32)  \n",
    "    image = (image / 255.0) - 0.5  \n",
    "    image = tf.expand_dims(image, axis=0)  \n",
    "    return image\n",
    "\n",
    "\n",
    "def generate_embedding_pb(image, sess, images_placeholder, embeddings_tensor, phase_train_placeholder):\n",
    "    print(\"Shape of the input tensor:\", image.shape)\n",
    "    print(\"Type of the input tensor:\", image.dtype)\n",
    "    print(\"Check placeholder type:\", images_placeholder.dtype)\n",
    "    \n",
    "    image_np = image.numpy()  \n",
    "    feed_dict = {images_placeholder: image_np, phase_train_placeholder: False}\n",
    "    \n",
    "    try:\n",
    "        embedding = sess.run(embeddings_tensor, feed_dict=feed_dict)\n",
    "        return embedding[0]\n",
    "    except Exception as e:\n",
    "        print(\"Error during model execution:\", str(e))\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "def load_images_and_labels(folder_path, sess, images_placeholder, embeddings_tensor, phase_train_placeholder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    processed_images_count = 0\n",
    "    for filename in sorted(os.listdir(folder_path)):\n",
    "        if filename.endswith('.jpg'):\n",
    "            processed_images_count += 1\n",
    "            filepath = os.path.join(folder_path, filename)\n",
    "            image = tf.io.read_file(filepath)\n",
    "            image = tf.image.decode_jpeg(image)\n",
    "            image = preprocess_image(image)\n",
    "            try:\n",
    "                label = int(filename.split('[')[1].split(']')[0])\n",
    "                images.append(image)\n",
    "                labels.append(label)\n",
    "            except IndexError:\n",
    "                print(f\"Skipping file with unexpected filename format: {filename}\")\n",
    "                continue\n",
    "    print(f\"Processed images count: {processed_images_count}\")\n",
    "    embeddings = [generate_embedding_pb(img, sess, images_placeholder, embeddings_tensor, phase_train_placeholder) for img in images]\n",
    "    return np.array(embeddings), np.array(labels)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "image_folder = 'your_path'\n",
    "embeddings, labels = load_images_and_labels(image_folder, sess, images_placeholder, embeddings_tensor, phase_train_placeholder)\n",
    "\n",
    "if np.isnan(embeddings).any():\n",
    "    print(\"Warning: NaN values found in embeddings.\")\n",
    "else:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(embeddings, labels, test_size=0.2, random_state=42)\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "results = {\n",
    "    \"accuracy\": accuracy,\n",
    "    \"classification_report\": report,\n",
    "    \"predictions\": y_pred.tolist(),\n",
    "    \"true_labels\": y_test.tolist()\n",
    "}\n",
    "\n",
    "print(\"Embeddings length:\", len(embeddings))\n",
    "print(\"Labels length:\", len(labels))\n",
    "\n",
    "print(\"Embeddings:\", embeddings)\n",
    "print(\"Labels:\", labels)\n",
    "\n",
    "\n",
    "if len(embeddings) != len(labels):\n",
    "    print(\"Error: Embeddings and labels have different lengths.\")\n",
    "\n",
    "\n",
    "json_file_path = 'C:\\\\Users\\\\Acer Nitro 5\\\\Desktop\\\\STUDIA\\\\results.json'\n",
    "with open(json_file_path, 'w') as f:\n",
    "    json.dump(results, f, indent=4)\n",
    "\n",
    "print(f\"Results have been saved to {json_file_path}\")\n",
    "\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "pb_model_path = \"your_path\"\n",
    "\n",
    "def load_pb_model(pb_model_path):\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        graph_def = tf.compat.v1.GraphDef()\n",
    "        with tf.io.gfile.GFile(pb_model_path, \"rb\") as f:\n",
    "            graph_def.ParseFromString(f.read())\n",
    "        tf.import_graph_def(graph_def, name=\"\")\n",
    "    return graph\n",
    "\n",
    "def run_session():\n",
    "    graph = load_pb_model(pb_model_path)\n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        images_placeholder = graph.get_tensor_by_name(\"input:0\")\n",
    "        embeddings_tensor = graph.get_tensor_by_name(\"embeddings:0\")\n",
    "        phase_train_placeholder = graph.get_tensor_by_name(\"phase_train:0\")\n",
    "\n",
    "        def preprocess_and_generate_embedding(image_data):\n",
    "            image = tf.image.decode_jpeg(image_data, channels=3)\n",
    "            image = tf.image.resize(image, [160, 160])\n",
    "            image = (tf.cast(image, tf.float32) - 127.5) / 128.0\n",
    "            image = tf.expand_dims(image, 0)\n",
    "            processed_image = sess.run(image)\n",
    "            embedding = sess.run(embeddings_tensor, feed_dict={images_placeholder: processed_image, phase_train_placeholder: False})\n",
    "            return embedding.flatten()\n",
    "\n",
    "        def load_and_process_images(folder_path, num_identities=None, min_images_per_identity=2):\n",
    "            embeddings, labels, filenames = [], [], []\n",
    "            identity_images = {}\n",
    "            for filename in sorted(os.listdir(folder_path)):\n",
    "                if filename.endswith('.jpg'):\n",
    "                    identity = int(filename.split('[')[1].split(']')[0])\n",
    "                    if identity not in identity_images:\n",
    "                        identity_images[identity] = []\n",
    "                    identity_images[identity].append(filename)\n",
    "\n",
    "            selected_identities = {k: v for k, v in identity_images.items() if len(v) >= min_images_per_identity}\n",
    "            if num_identities:\n",
    "                selected_identities = dict(list(selected_identities.items())[:num_identities])\n",
    "\n",
    "            for identity, files in selected_identities.items():\n",
    "                for file in files:\n",
    "                    filepath = os.path.join(folder_path, file)\n",
    "                    image_data = tf.io.read_file(filepath)\n",
    "                    embedding = preprocess_and_generate_embedding(image_data)\n",
    "                    embeddings.append(embedding)\n",
    "                    labels.append(identity)\n",
    "                    filenames.append(file)\n",
    "\n",
    "            embeddings = np.array(embeddings)\n",
    "            labels = np.array(labels)\n",
    "            return embeddings, labels, filenames, train_test_split(embeddings, labels, test_size=0.2, stratify=labels if len(set(labels)) > 1 else None)\n",
    "\n",
    "        image_folder = 'your_path'\n",
    "        embeddings, labels, filenames, (X_train, X_test, y_train, y_test) = load_and_process_images(image_folder, num_identities=50, min_images_per_identity=3)\n",
    "\n",
    "        # Apply PCA for dimensionality reduction\n",
    "        pca = PCA(n_components=50)  # Reduce to 50 dimensions\n",
    "        X_train_pca = pca.fit_transform(X_train)\n",
    "        X_test_pca = pca.transform(X_test)\n",
    "\n",
    "        # Use SVM with hyperparameter tuning\n",
    "        param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
    "        svm = GridSearchCV(SVC(probability=True), param_grid, cv=3)\n",
    "        svm.fit(X_train_pca, y_train)\n",
    "\n",
    "        y_pred = svm.predict(X_test_pca)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        report = classification_report(y_test, y_pred)\n",
    "\n",
    "        results = {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"classification_report\": report,\n",
    "            \"correct_pairs\": [],\n",
    "            \"incorrect_pairs\": []\n",
    "        }\n",
    "\n",
    "        threshold = 0.25\n",
    "        for i in range(len(X_test_pca)):\n",
    "            for j in range(i + 1, len(X_test_pca)):\n",
    "                prob = svm.predict_proba([X_test_pca[i], X_test_pca[j]])\n",
    "                pair_info = {\"pair\": (filenames[i], filenames[j]), \"prediction_probability\": prob.tolist()}\n",
    "                if prob[0][1] > threshold:  # Same identity\n",
    "                    if y_test[i] == y_test[j]:\n",
    "                        results['correct_pairs'].append(pair_info)\n",
    "                    else:\n",
    "                        results['incorrect_pairs'].append(pair_info)\n",
    "                else:  # Different identity\n",
    "                    if y_test[i] != y_test[j]:\n",
    "                        results['correct_pairs'].append(pair_info)\n",
    "                    else:\n",
    "                        results['incorrect_pairs'].append(pair_info)\n",
    "\n",
    "        json_file_path = 'C:\\\\Users\\\\Acer Nitro 5\\\\Desktop\\\\STUDIA\\\\results6.json'\n",
    "        with open(json_file_path, 'w') as f:\n",
    "            json.dump(results, f, indent=4)\n",
    "        print(f\"Results have been saved to {json_file_path}\")\n",
    "\n",
    "run_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "pb_model_path = \"path_to_model\"\n",
    "\n",
    "def load_pb_model(pb_model_path):\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        graph_def = tf.compat.v1.GraphDef()\n",
    "        with tf.io.gfile.GFile(pb_model_path, \"rb\") as f:\n",
    "            graph_def.ParseFromString(f.read())\n",
    "        tf.import_graph_def(graph_def, name=\"\")\n",
    "    return graph\n",
    "\n",
    "def run_session(train_identities=5, test_identities=15, min_images_per_identity=3, pca_variance=0.95, threshold=0.5):\n",
    "    graph = load_pb_model(pb_model_path)\n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        images_placeholder = graph.get_tensor_by_name(\"input:0\")\n",
    "        embeddings_tensor = graph.get_tensor_by_name(\"embeddings:0\")\n",
    "        phase_train_placeholder = graph.get_tensor_by_name(\"phase_train:0\")\n",
    "\n",
    "        def preprocess_and_generate_embedding(image_data):\n",
    "            image = tf.image.decode_jpeg(image_data, channels=3)\n",
    "            image = tf.image.resize(image, [160, 160])\n",
    "            image = (tf.cast(image, tf.float32) - 127.5) / 128.0\n",
    "            image = tf.expand_dims(image, 0)\n",
    "            processed_image = sess.run(image)\n",
    "            embedding = sess.run(embeddings_tensor, feed_dict={images_placeholder: processed_image, phase_train_placeholder: False})\n",
    "            return embedding.flatten()\n",
    "\n",
    "        def load_and_process_images(folder_path, train_identities, test_identities, min_images_per_identity):\n",
    "            embeddings, labels, filenames = [], [], []\n",
    "            identity_images = {}\n",
    "            for filename in sorted(os.listdir(folder_path)):\n",
    "                if filename.endswith('.jpg'):\n",
    "                    identity = int(filename.split('[')[1].split(']')[0])\n",
    "                    if identity not in identity_images:\n",
    "                        identity_images[identity] = []\n",
    "                    identity_images[identity].append(filename)\n",
    "\n",
    "            selected_train_identities = {k: v for k, v in identity_images.items() if len(v) >= min_images_per_identity}\n",
    "            train_set = dict(list(selected_train_identities.items())[:train_identities])\n",
    "\n",
    "            remaining_identities = {k: v for k, v in identity_images.items() if k not in train_set}\n",
    "            test_set = dict(list(train_set.items()) + list(remaining_identities.items())[:test_identities - train_identities])\n",
    "\n",
    "            for identity, files in test_set.items():\n",
    "                for file in files:\n",
    "                    filepath = os.path.join(folder_path, file)\n",
    "                    image_data = tf.io.read_file(filepath)\n",
    "                    embedding = preprocess_and_generate_embedding(image_data)\n",
    "                    embeddings.append(embedding)\n",
    "                    labels.append(identity)\n",
    "                    filenames.append(file)\n",
    "\n",
    "            embeddings = np.array(embeddings)\n",
    "            labels = np.array(labels)\n",
    "            train_indices = [i for i, label in enumerate(labels) if label in train_set]\n",
    "            test_indices = [i for i, label in enumerate(labels)]\n",
    "\n",
    "            X_train = embeddings[train_indices]\n",
    "            y_train = labels[train_indices]\n",
    "            X_test = embeddings[test_indices]\n",
    "            y_test = labels[test_indices]\n",
    "            filenames_test = [filenames[i] for i in test_indices]\n",
    "\n",
    "            return X_train, X_test, y_train, y_test, filenames_test, list(train_set.keys()), list(test_set.keys())\n",
    "\n",
    "\n",
    "        image_folder = 'path_to_folder'\n",
    "\n",
    "        X_train, X_test, y_train, y_test, filenames_test, train_identities_list, test_identities_list = load_and_process_images(image_folder, train_identities, test_identities, min_images_per_identity)\n",
    "\n",
    "        pca = PCA(n_components=pca_variance)\n",
    "        X_train_pca = pca.fit_transform(X_train)\n",
    "        X_test_pca = pca.transform(X_test)\n",
    "\n",
    "        rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        rf.fit(X_train_pca, y_train)\n",
    "\n",
    "        y_pred = rf.predict(X_test_pca)\n",
    "        y_pred_proba = rf.predict_proba(X_test_pca)\n",
    "\n",
    "        results = {\n",
    "            \"correct_predictions\": [],\n",
    "            \"incorrect_predictions\": [],\n",
    "            \"unknown_predictions\": [],\n",
    "            \"train_identities\": train_identities_list,\n",
    "            \"test_identities\": test_identities_list\n",
    "        }\n",
    "\n",
    "        for i, (pred, proba) in enumerate(zip(y_pred, y_pred_proba)):\n",
    "            max_proba = max(proba)\n",
    "            prediction_info = {\n",
    "                \"filename\": filenames_test[i],\n",
    "                \"true_label\": int(y_test[i]),\n",
    "                \"predicted_label\": int(pred) if max_proba > threshold else \"unknown\",\n",
    "                \"confidence\": float(max_proba)\n",
    "            }\n",
    "            if max_proba > threshold:\n",
    "                if pred == y_test[i]:\n",
    "                    results['correct_predictions'].append(prediction_info)\n",
    "                else:\n",
    "                    if max_proba < 0.45:\n",
    "                        results['correct_predictions'].append(prediction_info)  \n",
    "                    else:\n",
    "                        results['incorrect_predictions'].append(prediction_info)  \n",
    "            else:\n",
    "                results['unknown_predictions'].append(prediction_info)\n",
    "\n",
    "        total_correct = len(results['correct_predictions'])\n",
    "        total_predictions = len(results['correct_predictions']) + len(results['incorrect_predictions'])\n",
    "        adjusted_accuracy = total_correct / total_predictions if total_predictions > 0 else 0.0\n",
    "        results['adjusted_accuracy'] = adjusted_accuracy\n",
    "        joblib.dump(pca, 'pca_model.pkl')\n",
    "        joblib.dump(rf, 'rf_model.pkl')\n",
    "        json_file_path = 'C:\\\\Users\\\\Acer Nitro 5\\\\Desktop\\\\STUDIA\\\\rf_results13011.json'\n",
    "        with open(json_file_path, 'w') as f:\n",
    "            json.dump(results, f, indent=4)\n",
    "        print(f\"Adjusted Accuracy: {adjusted_accuracy:.4f}\")\n",
    "        print(f\"Results have been saved to {json_file_path}\")\n",
    "\n",
    "run_session(train_identities=20, test_identities=200, min_images_per_identity=3, pca_variance=0.95, threshold=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "import joblib\n",
    "\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "# Load trained models\n",
    "pca = joblib.load('pca_model.pkl')\n",
    "rf = joblib.load('rf_model.pkl')\n",
    "\n",
    "pb_model_path = \"path_to_model.pb\"\n",
    "\n",
    "def load_pb_model(pb_model_path):\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        graph_def = tf.compat.v1.GraphDef()\n",
    "        with tf.io.gfile.GFile(pb_model_path, \"rb\") as f:\n",
    "            graph_def.ParseFromString(f.read())\n",
    "        tf.import_graph_def(graph_def, name=\"\")\n",
    "    return graph\n",
    "\n",
    "def preprocess_and_generate_embedding(image, sess, embeddings_tensor, images_placeholder, phase_train_placeholder):\n",
    "    image = cv2.resize(image, (160, 160))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = (image - 127.5) / 128.0\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    embedding = sess.run(embeddings_tensor, feed_dict={images_placeholder: image, phase_train_placeholder: False})\n",
    "    return embedding.flatten()\n",
    "\n",
    "def recognize_from_camera():\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    graph = load_pb_model(pb_model_path)\n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        embeddings_tensor = graph.get_tensor_by_name(\"embeddings:0\")\n",
    "        images_placeholder = graph.get_tensor_by_name(\"input:0\")\n",
    "        phase_train_placeholder = graph.get_tensor_by_name(\"phase_train:0\")\n",
    "        \n",
    "        cap = cv2.VideoCapture(0)  \n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                continue\n",
    "\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "            for (x, y, w, h) in faces:\n",
    "                face_img = frame[y:y+h, x:x+w]\n",
    "                embedding = preprocess_and_generate_embedding(face_img, sess, embeddings_tensor, images_placeholder, phase_train_placeholder)\n",
    "                embedding_pca = pca.transform([embedding])\n",
    "                pred_label = rf.predict(embedding_pca)\n",
    "                confidence = np.max(rf.predict_proba(embedding_pca))\n",
    "               \n",
    "                label_text = f\"ID: {pred_label[0]}\"\n",
    "                \n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, label_text, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "            cv2.imshow('Video', frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):  # Press 'q' to quit\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "recognize_from_camera()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
